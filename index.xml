<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hong-Yu&#39;s Homepage on Hong-Yu&#39;s Homepage</title>
    <link>https://funnyzhou.github.io/index.xml</link>
    <description>Recent content in Hong-Yu&#39;s Homepage on Hong-Yu&#39;s Homepage</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016 Your Name</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Adaptive Feeding: Achieving Fast and Accurate Detections by Adaptively Combining Object Detectors</title>
      <link>https://funnyzhou.github.io/project/adaptive_feeding/</link>
      <pubDate>Sat, 29 Jul 2017 22:31:54 +0800</pubDate>
      
      <guid>https://funnyzhou.github.io/project/adaptive_feeding/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://funnyzhou.github.io/post/img/arch_af.png&#34; alt=&#34;image0&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;

&lt;p&gt;Object detection aims at high speed and accuracy simultaneously. However, fast models are usually less accurate, while accurate models cannot satisfy our need for speed. A fast model can be 10 times faster but 50% less accurate than an accurate model. In this paper, we propose Adaptive Feeding (AF) to combine a fast (but less accurate) detector and an accurate (but slow) detector, by adaptively determining whether an image is easy or hard and choosing an appropriate detector for it. In practice, we build a cascade of detectors, including the AF classifier which make the easy vs. hard decision and the two detectors. The AF classifier can be tuned to obtain different tradeoff between speed and accuracy, which has negligible training time and requires no additional training data. Experimental results on the PASCAL VOC, MS COCO and Caltech Pedestrian datasets confirm that AF has the ability to achieve comparable speed as the fast detector and comparable accuracy as the accurate one at the same time. As an example, by combining the fast SSD300 with the accurate SSD500 detector, AF leads to 50% speedup over SSD500 with the same precision on the VOC2007 test set.&lt;/p&gt;

&lt;h3 id=&#34;basic-idea&#34;&gt;Basic Idea&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://funnyzhou.github.io/post/img/fig1.png&#34; alt=&#34;image1&#34; /&gt;&lt;img src=&#34;https://funnyzhou.github.io/post/img/table2.png&#34; alt=&#34;image2&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;experimental-results&#34;&gt;Experimental Results&lt;/h3&gt;

&lt;h4 id=&#34;pascal-voc-2007&#34;&gt;Pascal VOC 2007&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://funnyzhou.github.io/post/img/table4.png&#34; alt=&#34;image3&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;pascal-voc-2012&#34;&gt;Pascal VOC 2012&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://funnyzhou.github.io/post/img/table5.png&#34; alt=&#34;image4&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;publication&#34;&gt;Publication&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Adaptive Feeding: Achieving Fast and Accurate Detections by Adaptively Combining Object Detectors&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;  Hong-Yu Zhou, Bin-Bin Gao, Jianxin Wu&lt;/p&gt;

&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;  ICCV 2017　(poster) &lt;a href=&#34;https://arxiv.org/pdf/1707.06399.pdf&#34; target=&#34;_blank&#34;&gt;paper&lt;/a&gt; | &lt;a href=&#34;https://arxiv.org/abs/1707.06399&#34; target=&#34;_blank&#34;&gt;arXiv&lt;/a&gt; | Slide | Video | Poster&lt;/p&gt;

&lt;h3 id=&#34;downloads&#34;&gt;Downloads&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Code [coming soon]&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;acknowledgements&#34;&gt;Acknowledgements&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;This work was supported in part by the National Natural Science Foundation of China under Grant No. 61422203.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Weakly Supervised CNN</title>
      <link>https://funnyzhou.github.io/project/weakly_supervised_cnn/</link>
      <pubDate>Sat, 29 Jul 2017 22:26:47 +0800</pubDate>
      
      <guid>https://funnyzhou.github.io/project/weakly_supervised_cnn/</guid>
      <description>&lt;p&gt;This is an implementation of the method in &lt;strong&gt;Is object localization for free? – Weakly-supervised learning with convolutional neural networks&lt;/strong&gt; using MatConvNet. For more details, please refer to &lt;a href=&#34;https://github.com/funnyzhou/weakcnn&#34; target=&#34;_blank&#34;&gt;this link&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://funnyzhou.github.io/post/img/weakcnn.png&#34; alt=&#34;image1&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CAM in MatConvNet</title>
      <link>https://funnyzhou.github.io/project/cam_matconvnet/</link>
      <pubDate>Sat, 29 Jul 2017 22:19:54 +0800</pubDate>
      
      <guid>https://funnyzhou.github.io/project/cam_matconvnet/</guid>
      <description>&lt;p&gt;This is an implementation of the method in &lt;strong&gt;Learning Deep Features for Discriminative Localization&lt;/strong&gt; using MatConvNet. For more details, please refer to &lt;a href=&#34;https://github.com/funnyzhou/CAM_MatConvNet&#34; target=&#34;_blank&#34;&gt;this link&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://funnyzhou.github.io/post/img/ex1.png&#34; alt=&#34;image1&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Adaptive Feeding: Achieving Fast and Accurate Detections by Adaptively Combining Object Detectors</title>
      <link>https://funnyzhou.github.io/publication/adaptive-feeding/</link>
      <pubDate>Sat, 29 Jul 2017 22:08:21 +0800</pubDate>
      
      <guid>https://funnyzhou.github.io/publication/adaptive-feeding/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Recognizing Subtle Differences: Sunrise or Sunset?</title>
      <link>https://funnyzhou.github.io/publication/sos/</link>
      <pubDate>Sat, 29 Jul 2017 21:59:30 +0800</pubDate>
      
      <guid>https://funnyzhou.github.io/publication/sos/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Content-Based Image Recovery</title>
      <link>https://funnyzhou.github.io/publication/content-recovery/</link>
      <pubDate>Sat, 29 Jul 2017 21:59:27 +0800</pubDate>
      
      <guid>https://funnyzhou.github.io/publication/content-recovery/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Awesome object detection</title>
      <link>https://funnyzhou.github.io/post/awesome-object-detection/</link>
      <pubDate>Thu, 30 Mar 2017 16:16:26 +0800</pubDate>
      
      <guid>https://funnyzhou.github.io/post/awesome-object-detection/</guid>
      <description>

&lt;p&gt;A curated list of resources I have read or used. Besides, each material is attached with a short piece of abstract.&lt;/p&gt;

&lt;h1 id=&#34;updated-30-03-2017&#34;&gt;(updated 30/03/2017)&lt;/h1&gt;

&lt;h2 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#papers&#34;&gt;Papers&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#r-cnn&#34;&gt;R-CNN Series&lt;/a&gt; (&lt;a href=&#34;#sec1_2017&#34;&gt;2017&lt;/a&gt; &lt;a href=&#34;#sec1_2016&#34;&gt;2016&lt;/a&gt; &lt;a href=&#34;#sec1_2015&#34;&gt;2015&lt;/a&gt; &lt;a href=&#34;#sec1_2014&#34;&gt;2014&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ssd&#34;&gt;Single Shot Detectors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#understanding&#34;&gt;Towards A Better Understanding&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#performance&#34;&gt;Performance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tutorials&#34;&gt;Tutorials&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;papers&#34;&gt;Papers&lt;/h2&gt;

&lt;h3 id=&#34;r-cnn-series&#34;&gt;R-CNN Series&lt;/h3&gt;

&lt;h4 id=&#34;2015&#34;&gt;2015&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Faster R-CNN&lt;a href=&#34;https://github.com/ShaoqingRen/faster_rcnn&#34; target=&#34;_blank&#34;&gt;[Code_Matlab]&lt;/a&gt;&lt;a href=&#34;https://github.com/rbgirshick/py-faster-rcnn&#34; target=&#34;_blank&#34;&gt;[Code_Python]&lt;/a&gt;&lt;a href=&#34;https://github.com/CharlesShang/TFFRCNN&#34; target=&#34;_blank&#34;&gt;[Code_Tensorflow]&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun. &lt;a href=&#34;https://arxiv.org/pdf/1506.01497.pdf&#34; target=&#34;_blank&#34;&gt;Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks&lt;/a&gt;, TPAMI, 2016. (An older version appeared in NIPS 2015)&lt;/li&gt;
&lt;li&gt;Summary: &lt;strong&gt;A Region Proposal Network (RPN).&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Code note: The python version is mostly used.
&lt;/br&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Fast R-CNN&lt;a href=&#34;https://github.com/rbgirshick/fast-rcnn&#34; target=&#34;_blank&#34;&gt;[Code_Python]&lt;/a&gt;&lt;a href=&#34;https://github.com/ShaoqingRen/faster_rcnn&#34; target=&#34;_blank&#34;&gt;[Code_Matlab]&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Ross Girshick. &lt;a href=&#34;https://arxiv.org/pdf/1504.08083.pdf&#34; target=&#34;_blank&#34;&gt;Fast R-CNN&lt;/a&gt;, ICCV, 2015.&lt;/li&gt;
&lt;li&gt;Summary: &lt;strong&gt;The basic network architecture for later R-CNN based researches.&lt;/strong&gt;
&lt;/br&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Multibox_v2 &lt;a href=&#34;https://github.com/google/multibox&#34; target=&#34;_blank&#34;&gt;[Code]&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Christian Szegedy, Scott Reed, Dumitru Erhan, Dragomir Anguelov, Sergey Ioffe. &lt;a href=&#34;https://arxiv.org/pdf/1412.1441.pdf&#34; target=&#34;_blank&#34;&gt;Scalable High Quality Object Detection&lt;/a&gt;, CVPR, 2015.&lt;/li&gt;
&lt;li&gt;Summary: &lt;strong&gt;The basic idea is similar to RPN&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;2014&#34;&gt;2014&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;R-CNN &lt;a href=&#34;https://github.com/rbgirshick/rcnn&#34; target=&#34;_blank&#34;&gt;[Code]&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Ross Girshick, Jeff Donahue, Trevor Darrell, Jitendra Malik. &lt;a href=&#34;https://arxiv.org/pdf/1311.2524.pdf&#34; target=&#34;_blank&#34;&gt;Rich feature hierarchies for accurate object detection and semantic segmentation&lt;/a&gt;, CVPR, 2014.&lt;/li&gt;
&lt;li&gt;Summary: &lt;strong&gt;The first time object detection combined with deep learning.&lt;/strong&gt;
&lt;/br&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Multibox_v1 &lt;a href=&#34;https://github.com/google/multibox&#34; target=&#34;_blank&#34;&gt;[Code]&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Dumitru Erhan, Christian Szegedy, Alexander Toshev, Dragomir Anguelov. &lt;a href=&#34;https://arxiv.org/pdf/1312.2249.pdf&#34; target=&#34;_blank&#34;&gt;Scalable Object Detection using Deep Neural Networks&lt;/a&gt;, CVPR, 2014.&lt;/li&gt;
&lt;li&gt;Summary: &lt;strong&gt;This paper tought us that we can generate proposals by using a deep neural network.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Example Talk</title>
      <link>https://funnyzhou.github.io/talk/example-talk/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://funnyzhou.github.io/talk/example-talk/</guid>
      <description>&lt;p&gt;Embed your slides or video here using &lt;a href=&#34;https://gcushen.github.io/hugo-academic-demo/post/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;shortcodes&lt;/a&gt;. Further details can easily be added using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
